{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join, exists\n",
    "from time import clock\n",
    "\n",
    "datapath = '/cluster/work/grlab/clinical/Inselspital/DataReleases/01-19-2017/InselSpital/'\n",
    "data_version = '180822'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consent_patient = get_consent_patient_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(consent_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datapath():\n",
    "    return datapath\n",
    "\n",
    "def get_table_names(tbl_type='all'):\n",
    "    tbl_list = ['monvals', 'comprvals', 'dervals', 'observrec', 'labres', 'pharmarec']\n",
    "    if tbl_type == 'all':\n",
    "        return tbl_list \n",
    "    elif tbl_type == 'pharma':\n",
    "        return ['pharmarec']\n",
    "    elif tbl_type == 'non-pharma':\n",
    "        return tbl_list[:-1]\n",
    "\n",
    "def get_status_str(statusID, tbl_name):\n",
    "    '''\n",
    "    Get the meaning of a status\n",
    "    '''\n",
    "    status_str = []\n",
    "    if tbl_name == 'pharmarec':\n",
    "        statusID_bin_str = '{0:10b}'.format(statusID)[::-1]\n",
    "        if statusID_bin_str[1] == '1':\n",
    "            status_str.append('invalidated')\n",
    "        if statusID_bin_str[2] == '1':\n",
    "            status_str.append('start')\n",
    "        if statusID_bin_str[3] == '1':\n",
    "            status_str.append('caused by event')\n",
    "        if statusID_bin_str[5] == '1':\n",
    "            status_str.append('notified')\n",
    "        if statusID_bin_str[8] == '1':\n",
    "            status_str.append('stop')\n",
    "        if statusID_bin_str[9] == '1':\n",
    "            status_str.append('included in record reports')\n",
    "    else:\n",
    "        statusID_bin_str = '{0:11b}'.format(statusID)[::-1]\n",
    "        if statusID_bin_str[0] == '1':\n",
    "            status_str.append('out of range')\n",
    "        if statusID_bin_str[1] == '1':\n",
    "            status_str.append('invalidated')\n",
    "        if statusID_bin_str[2] == '1':\n",
    "            status_str.append('first of connection')\n",
    "        if statusID_bin_str[3] == '1':\n",
    "            status_str.append('caused by event')\n",
    "        if statusID_bin_str[4] == '1':\n",
    "            status_str.append('compressed')\n",
    "        if statusID_bin_str[5] == '1':\n",
    "            status_str.append('notified but not measured')\n",
    "        if statusID_bin_str[6] == '1':\n",
    "            status_str.append('bigger than')\n",
    "        if statusID_bin_str[7] == '1':\n",
    "            status_str.append('smaller than')\n",
    "        if statusID_bin_str[10] == '1':\n",
    "            status_str.append('mandatory')\n",
    "            \n",
    "    return ', '.join(status_str)\n",
    "\n",
    "def voi_id_name_mapping(tbl_name, replace_name=False, include_all=False, use_ref='excel', version='v6'):\n",
    "    \"\"\"\n",
    "    Load the mapping between variableID and variableName\n",
    "    \n",
    "    Parameters:\n",
    "    tbl_name: the name of the table (string)\n",
    "    replace_name: bool; if True, the variableNames are the medical terms; otherwise, the varialbeName\n",
    "    are the 'v%s'%variableIDs.\n",
    "    include_all: bool; if True, all the variables in the table are variables of interest; otherwise,\n",
    "    only variables can be found in the ref_excel files are the variables of interest.\n",
    "\n",
    "    Returns:\n",
    "    voi: dataframe; include the mapping between variableIDs and variableNames of the variables of\n",
    "    interest\n",
    "    \"\"\"\n",
    "    if use_ref not in ['excel', 'expot']:\n",
    "        raise Exception('use_ref can only be \"excel\" or \"expot\"')\n",
    "    id_list_path = join(datapath, 'misc_derived', 'id_lists')\n",
    "    excelref_path = join(datapath, 'misc_derived', 'ref_excel')\n",
    "    expotref_path = join(datapath, '0_csv_exports')\n",
    "    vid_set = pd.read_csv(join(id_list_path, 'vID_%s.csv'%tbl_name), sep=',',\n",
    "                          dtype={'VariableID': int}).VariableID.unique()\n",
    "\n",
    "    # The head of the variable name is 'v' is the variable is non-pharma variable;\n",
    "    # otherwise the variable name head is 'p' \n",
    "    vname_head = 'p' if tbl_name == 'pharmarec' else 'v' \n",
    "    if include_all and not replace_name:\n",
    "        ref_voi = pd.DataFrame([[x, '%s%d'%(vname_head, x)] for x in vid_set], \n",
    "                               columns=['VariableID', 'VariableName'])\n",
    "    else:\n",
    "        excelref_filename = 'labref_excel_%s.tsv'%version if tbl_name == 'labres' else 'varref_excel_%s.tsv'%version\n",
    "\n",
    "        excelref = pd.read_csv(join(excelref_path, excelref_filename), sep='\\t', encoding='cp1252')\n",
    "        \n",
    "        # Avoid repeat VariableIDs in 'pharmarec' and other tables\n",
    "        if tbl_name == 'pharmarec':\n",
    "            excelref = excelref[excelref.Type=='Pharma']\n",
    "        elif tbl_name != 'labres':\n",
    "            excelref = excelref[excelref.Type!='Pharma']\n",
    "        try:\n",
    "            excelref['VariableID'] = excelref['VariableID'].astype(int)\n",
    "        except:\n",
    "            excelref['VariableID'] = excelref.VariableID.apply(lambda x: float('NaN') if x=='???' else float(x))\n",
    "\n",
    "        if not include_all and not replace_name:\n",
    "            vid_voi = set(excelref.VariableID) & set(vid_set)\n",
    "            ref_voi = pd.DataFrame([[x, '%s%d'%(vname_head, x)] for x in vid_voi], \n",
    "                                   columns=['VariableID', 'VariableName'])\n",
    "        else:\n",
    "            if tbl_name == 'pharmarec':\n",
    "                expotref = pd.read_csv(join(expotref_path, 'expot-pharmaref.csv'), sep='\\t', encoding='cp1252',\n",
    "                                       usecols=['PharmaID', 'PharmaName']).drop_duplicates('PharmaID', keep='last')\n",
    "                expotref.rename(columns={'PharmaID': 'VariableID', 'PharmaName': 'VariableName'}, inplace=True)\n",
    "            else:\n",
    "                expotref = pd.read_csv(join(expotref_path, 'expot-varref.csv'), sep='\\t', encoding='cp1252',\n",
    "                                       usecols=['VariableID', 'Abbreviation']).drop_duplicates('VariableID', keep='last')\n",
    "                expotref.rename(columns={'Abbreviation': 'VariableName'}, inplace=True)\n",
    "\n",
    "            if include_all:\n",
    "                ref_voi = expotref[expotref.VariableID.isin(vid_set)].copy()\n",
    "                if use_ref == 'excel':\n",
    "                    print('Could not use the excel reference table when include_all=True, because the excel reference table is incomplete.')\n",
    "            else:            \n",
    "                vid_voi = set(excelref.VariableID) & set(vid_set)\n",
    "                if use_ref == 'excel':\n",
    "                    ref_voi = excelref[excelref.VariableID.isin(vid_voi)].copy()\n",
    "                else:\n",
    "                    ref_voi = expotref[excelref.VariableID.isin(vid_voi)].copy()\n",
    "            \n",
    "    ref_voi.VariableID = ref_voi.VariableID.astype(int)\n",
    "    ref_voi.VariableName = ref_voi.VariableName.astype(str)\n",
    "    ref_voi.set_index('VariableID', inplace=True)\n",
    "    return ref_voi\n",
    "\n",
    "def get_consent_patient_ids(recompute=False, replace=False):\n",
    "    \"\"\"\n",
    "    Return the list of patientID of patients with consent, i.e. those whose GeneralConsent \n",
    "    value smaller than 4 or not recorded in the observrec table, and not in the \n",
    "    PID_Exclusion_GeneralConsent (sent by Martin) list\n",
    "    \"\"\"\n",
    "    id_list_path = join(datapath, 'misc_derived', 'id_lists')\n",
    "    filepath = join(id_list_path, 'PID_WithConsent_not_on_ECMO.csv')\n",
    "    if recompute:\n",
    "        df_gc = pd.read_csv(join(datapath, '0_csv_exports', 'expot-observrec.csv'), sep=';',\n",
    "                            usecols=['PatientID', 'VariableID', 'Value'])\n",
    "        pid_exclude = set(pd.read_csv(join(id_list_path, 'PID_Exclusion_GeneralConsent.csv')).PatientID) | set(pd.read_csv(join(id_list_path, 'PID_on_ECMO.csv')).PatientID)\n",
    "        df_gc = df_gc[df_gc.VariableID == 15004651] # extract time series of GeneralConsent\n",
    "        df_gc.loc[:,'Value'] = df_gc.Value.astype(float)\n",
    "        pid_noconsent = set(df_gc[df_gc.Value >= 4].PatientID)\n",
    "        pid_gd = set(pd.read_csv(join(datapath, '0_csv_exports', 'expot-generaldata.csv'), sep=';',\n",
    "                                 usecols=['PatientID']).PatientID)\n",
    "        pid_any_but_gd = set()\n",
    "        for tbl in get_table_names():\n",
    "            pid_tbl_filepath = join(id_list_path, 'PID_%s.csv'%tbl)\n",
    "            if not exists(pid_tbl_filepath):\n",
    "                import ipdb\n",
    "                ipdb.set_trace()\n",
    "                if tbl in ['monvals', 'comprvals']:\n",
    "                    csv_iters = pd.read_csv(join(datapath, '0_csv_exports', 'expot-%s.csv'%tbl), sep=';',\n",
    "                                            usecols=['PatientID'], chunksize=10**7)\n",
    "                    pid_tbl = set()\n",
    "                    for i, chunk in enumerate(csv_iters):\n",
    "                        pid_tbl = pid_tbl | set(chunk.PatientID)\n",
    "                else:\n",
    "                    df_tmp = pd.read_csv(join(datapath, '0_csv_exports', 'expot-%s.csv'%tbl),\n",
    "                                         usecols=['PatientID'], sep=';')\n",
    "                    pid_tbl = set(df_tmp.PatientID)\n",
    "                df_pid_tbl = pd.DataFrame(list(pid_tbl), columns=['PatientID'])\n",
    "                df_pid_tbl.to_csv(pid_tbl_filepath, index=False)\n",
    "            else:\n",
    "                pid_tbl = set(pd.read_csv(pid_tbl_filepath).PatientID)\n",
    "            print('# patients in %s: %d'%(tbl, len(pid_tbl)))\n",
    "            pid_any_but_gd = pid_any_but_gd | pid_tbl\n",
    "        pid_any_and_gd = pid_any_but_gd & pid_gd \n",
    "        pid_gd_include = pid_gd - (pid_exclude | pid_noconsent)\n",
    "        pid_any_but_gd_include = pid_any_but_gd - (pid_exclude | pid_noconsent)\n",
    "        pid_include = list((pid_any_but_gd | pid_gd) - (pid_gd - pid_any_but_gd) - (pid_exclude | pid_noconsent))\n",
    "\n",
    "        print('# patients in any measurement tables but generaldata: %d'%(len(pid_any_but_gd)))\n",
    "        print('# patients in generaldata: %d'%(len(pid_gd)))\n",
    "        print('# patients in any measurement tables but also in generaldata: %d'%(len(pid_any_and_gd)))\n",
    "        print('# patients in generaldata but have no measurement: %d'%(len(pid_gd - pid_any_but_gd)))\n",
    "        print('# patients have measurement but not in generaldata: %d'%(len(pid_any_but_gd - pid_gd)))\n",
    "        print('# patients in \"PID_Exclusion_GeneralConsent.csv\": %d'%(len(pid_exclude)))\n",
    "        print('# patients in \"PID_Exclusion_GeneralConsent.csv\" but not in general data: %d'%(len(pid_exclude - pid_gd)))\n",
    "        print('# patients whose GeneralConsent value >= 4: %d'%(len(pid_noconsent)))\n",
    "        print('# patients whose GeneralConsent >=4 and are also in \"PID_Exclusion_GeneralConsent.csv\": %d'%len(pid_exclude & pid_noconsent))\n",
    "        print('# patients in generaldata who give consent: %d'%(len(pid_gd_include)))\n",
    "        print('# patients in any measurement table but general who give consent: %d'%(len(pid_any_but_gd_include)))\n",
    "        print('# patients who give consent and have measurement data: %d'%(len(pid_include)))\n",
    "\n",
    "        df_pid_include = pd.DataFrame(pid_include, columns=['PatientID'])\n",
    "        if replace:\n",
    "            df_pid_include.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        pid_include = pd.read_csv(filepath, sep=',').PatientID.unique()\n",
    "    pid_include = np.sort(pid_include)\n",
    "    return pid_include\n",
    "\n",
    "def get_patients_admitted_later(year=2008, rewrite=False):\n",
    "    pid_list_file = join(datapath, 'misc_derived', 'id_lists', 'PID_WithConsent_AdmittedAfter%d_not_on_ECMO.csv'%year)\n",
    "    if not exists(pid_list_file) or rewrite:\n",
    "        static = pd.read_csv(join(datapath, '0_csv_exports', 'expot-generaldata.csv'), usecols=['PatientID', 'AdmissionTime'], sep=';')\n",
    "        pids_with_consent = get_consent_patient_ids()\n",
    "        static = static[static.PatientID.isin(pids_with_consent)].copy()\n",
    "        static['AdmissionTime'] = pd.to_datetime(static['AdmissionTime'])\n",
    "\n",
    "        pid_list = static[static.AdmissionTime.apply(lambda x: x.year >= year)].PatientID.unique()\n",
    "        df = pd.DataFrame(pid_list.reshape((-1,1)), columns=['PatientID'])\n",
    "        df.to_csv(pid_list_file, index=False)\n",
    "    else:\n",
    "        pid_list = np.array(pd.read_csv(pid_list_file).PatientID)\n",
    "    pid_list = np.sort(pid_list)\n",
    "    return pid_list\n",
    "\n",
    "def load_chunkfile_index(num_chunks=50, rewrite=False):\n",
    "    chunkfile_index_file = join(datapath, 'misc_derived', 'id_lists', 'PID_%dchunkfile_index_not_on_ECMO.csv'%num_chunks)\n",
    "    if not exists(chunkfile_index_file) or rewrite:\n",
    "        pid_list = get_patients_admitted_later()\n",
    "        chunksize = int(np.ceil( len(pid_list) / num_chunks))\n",
    "        chunkfile_index = []\n",
    "        for i in range(num_chunks):\n",
    "            idx_start = i*chunksize\n",
    "            idx_stop = min((i+1)*chunksize, len(pid_list))\n",
    "            pid_list_tmp = pid_list[idx_start:idx_stop]\n",
    "            chunkfile_index.extend([[pid, i] for pid in pid_list_tmp])\n",
    "        chunkfile_index = pd.DataFrame(np.array(chunkfile_index), columns=['PatientID', 'ChunkfileIndex'])\n",
    "        chunkfile_index.to_csv(chunkfile_index_file, index=False)\n",
    "    else:\n",
    "        chunkfile_index = pd.read_csv(chunkfile_index_file)\n",
    "    chunkfile_index = chunkfile_index.set_index('PatientID')\n",
    "    return chunkfile_index\n",
    "        \n",
    "def get_subset_patient_ids():\n",
    "    \"\"\"\n",
    "    Return the list of patientID of 5% of the patients with consent\n",
    "    \"\"\"\n",
    "    id_list_path = join(datapath, 'misc_derived', 'id_lists')\n",
    "    filepath = join(id_list_path, 'PID_Subset.csv')\n",
    "    if not exists(filepath):\n",
    "        GetValidPidList()\n",
    "        np.random.seed(0)\n",
    "        tmp = np.random.rand(len(pID_set))\n",
    "        pID_subset = pID_set[tmp <= .05] # choose only 5% of the patient\n",
    "        df_pID_subset = pd.DataFrame(pID_subset, columns=['PatientID'])\n",
    "        df_pID_subset.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        pID_subset = pd.read_csv(filepath).PatientID.unique()\n",
    "    return pID_subset\n",
    "\n",
    "def time_difference(t_early, t_later):\n",
    "    \"\"\"\n",
    "    Compute the time difference between t_early and t_later\n",
    "\n",
    "    Parameters:\n",
    "    t_early: np.datetime64, list or pandas series.\n",
    "    t_later: np.datetime64, list or pandas series.\n",
    "    \"\"\"\n",
    "    if type(t_early) == list:\n",
    "        t1 = np.array(t_early)\n",
    "    elif type(t_early) == pd.Series:\n",
    "        t1 = np.array(t_early.tolist())\n",
    "    else:\n",
    "        t1 = np.array([t_early])\n",
    "\n",
    "    if type(t_later) == list:\n",
    "        t2 = np.array(t_later)\n",
    "    elif type(t_later) == pd.Series:\n",
    "        t2 = np.array(t_later.tolist())\n",
    "    else:\n",
    "        t2 = np.array([t_later])\n",
    "\n",
    "    timedelta2float = np.vectorize(lambda x: x / np.timedelta64(3600, 's'))\n",
    "    t_diff = timedelta2float(t2 - t1)\n",
    "    return t_diff\n",
    "\n",
    "def get_all_var_names():\n",
    "    tbl_list = ['monvals', 'comprvals', 'dervals', 'observrec', 'pharmarec', 'labres']\n",
    "    vname_list = []\n",
    "    for tbl in tbl_list:\n",
    "        ref_voi = voi_id_name_mapping(tbl)\n",
    "        vname_list.append(ref_voi.VariableName.unique())\n",
    "    vname_list = np.unique(np.concatenate(tuple(vname_list)))\n",
    "    return vname_list\n",
    "\n",
    "def read_single_patient_from_merged(patient_id, vname_list=None, verbose=False):\n",
    "    readpath = join(datapath, '3_merged', 'fmat_170327')\n",
    "    t = clock()\n",
    "    if vname_list is None:\n",
    "        vname_list = get_all_var_names()\n",
    "    filename = 'p%s.h5'%patient_id\n",
    "    filepath = join(readpath, filename)\n",
    "    df = [pd.read_hdf(filepath, 'Datetime')]\n",
    "    for var_name in vname_list:\n",
    "        df.append(pd.read_hdf(filepath, var_name))\n",
    "    if verbose:\n",
    "        print('Time to read patient_id=%d: %g sec'%(patient_id, (clock()-t)))\n",
    "        t = clock()\n",
    "    df = pd.concat(df, axis=1, join_axes=[df[0].index])\n",
    "    if verbose:\n",
    "        print('Time to concate patient_id=%d: %g sec'%(patient_id, (clock()-t)))\n",
    "    return df\n",
    "  \n",
    "def generate_id2string():\n",
    "    tbl_list = ['monvals', 'comprvals', 'dervals', 'observrec', 'pharmarec', 'labres']\n",
    "    ref_list = []\n",
    "    for tbl in tbl_list:\n",
    "        ref = voi_id_name_mapping(tbl)\n",
    "        ref_string = voi_id_name_mapping(tbl, replace_name=True)\n",
    "        ref_string.columns = ['string']\n",
    "        ref['string'] = ref_string['string']\n",
    "        ref_list.append(ref)\n",
    "    ref = pd.concat(ref_list)\n",
    "    ref.reset_index(drop=True, inplace=True)\n",
    "    ref.columns = ['id', 'string']\n",
    "    ref.drop_duplicates(inplace=True)\n",
    "    ref.to_csv('id2string.csv', index=False)\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
